{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3affd2d7",
   "metadata": {},
   "source": [
    "Smurfette principle derivation, analysis of movie summaries, women are more often than not mentioned with a male character.\n",
    "\n",
    "Process the summary, and count how many times each character is mentioned, use n-grams (2-3 ?) to see when they are mentioned together.\n",
    "\n",
    "Maybe measure throughout the years ?\n",
    "\n",
    "Or measure with different n for n-grams, interactive plot ? (possible to do both yearly + variable n too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a7f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "import os\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "#Punctuations from python string.punctuation without the dot ('.'), additional punctuation added to remove artifacts\n",
    "punctuation = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '/', ':',\n",
    " ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'] + ['``', '\\'\\'', '\\'s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93256f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 450669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Freebase movie ID</th>\n",
       "      <th>Movie release date</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Actor date of birth</th>\n",
       "      <th>Actor gender</th>\n",
       "      <th>Actor height (in meters)</th>\n",
       "      <th>Actor ethnicity (Freebase ID)</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor age at movie release</th>\n",
       "      <th>Freebase character/actor map ID</th>\n",
       "      <th>Freebase character ID</th>\n",
       "      <th>Freebase actor ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.78</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia movie ID Freebase movie ID Movie release date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               Character name Actor date of birth Actor gender  \\\n",
       "0                    Akooshay          1958-08-26            F   \n",
       "1  Lieutenant Melanie Ballard          1974-08-15            F   \n",
       "\n",
       "   Actor height (in meters) Actor ethnicity (Freebase ID)          Actor name  \\\n",
       "0                      1.62                           NaN      Wanda De Jesus   \n",
       "1                      1.78                    /m/044038p  Natasha Henstridge   \n",
       "\n",
       "   Actor age at movie release Freebase character/actor map ID  \\\n",
       "0                        42.0                      /m/0bgchxw   \n",
       "1                        27.0                       /m/0jys3m   \n",
       "\n",
       "  Freebase character ID Freebase actor ID  \n",
       "0            /m/0bgcj3x        /m/03wcfv7  \n",
       "1            /m/0bgchn4         /m/0346l4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Character metadata\n",
    "char_md_cols = ['Wikipedia movie ID',\n",
    "'Freebase movie ID',\n",
    "'Movie release date',\n",
    "'Character name',\n",
    "'Actor date of birth',\n",
    "'Actor gender',\n",
    "'Actor height (in meters)',\n",
    "'Actor ethnicity (Freebase ID)',\n",
    "'Actor name',\n",
    "'Actor age at movie release',\n",
    "'Freebase character/actor map ID',\n",
    "'Freebase character ID',\n",
    "'Freebase actor ID',\n",
    "]\n",
    "char_md = pd.read_csv('data/character.metadata.tsv', sep='\\t', names=char_md_cols)\n",
    "print('Number of characters:', char_md.shape[0])\n",
    "char_md.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ca4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_gender = char_md[['Wikipedia movie ID', 'Character name', 'Actor gender']].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba53f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_movie_IDS = os.listdir(\"./data/corenlp_plot_summaries/\")\n",
    "wikipedia_movie_IDS = [filename.rsplit('.', 2)[0] for filename in wikipedia_movie_IDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6097228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42306"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikipedia_movie_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e373177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from xml.dom.minidom import parseString #, parse \n",
    "\n",
    "\n",
    "def open_parse_summary(wiki_id):\n",
    "    # open and read gzipped xml file\n",
    "    xml_file = gzip.open(\"./data/corenlp_plot_summaries/\" + wiki_id + \".xml.gz\")\n",
    "    document = parseString(xml_file.read())\n",
    "    \n",
    "    #Read all words\n",
    "    words = document.getElementsByTagName('word')\n",
    "    #lemmas = dom.getElementsByTagName('lemma')\n",
    "    \n",
    "    #Looks for the desired node type and extracts their values\n",
    "    words_list = [word.childNodes[0].nodeValue for word in words]\n",
    "    #lemmas_list = [lemma.childNodes[0].nodeValue for lemma in lemmas]\n",
    "    \n",
    "    return words_list#, lemmas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b0547b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26167604\n",
      "1/42306\n",
      "14075290\n",
      "2/42306\n",
      "24379585\n",
      "3/42306\n",
      "8683288\n",
      "4/42306\n",
      "18040146\n",
      "5/42306\n",
      "3113630\n",
      "6/42306\n",
      "15117612\n",
      "7/42306\n",
      "9404578\n",
      "8/42306\n",
      "21411112\n",
      "9/42306\n",
      "23553986\n",
      "10/42306\n",
      "9149984\n",
      "11/42306\n",
      "327582\n",
      "12/42306\n",
      "25375805\n",
      "13/42306\n",
      "5144523\n",
      "14/42306\n",
      "2817162\n",
      "15/42306\n",
      "24778429\n",
      "16/42306\n",
      "4298666\n",
      "17/42306\n",
      "8318237\n",
      "18/42306\n",
      "34383775\n",
      "19/42306\n",
      "15025803\n",
      "20/42306\n"
     ]
    }
   ],
   "source": [
    "#TODO: RERUN THIS ON DESKTOP TO PROCESS ALL THE SUMMARIES\n",
    "\n",
    "# DO NOT RUN UNLESS NECESSARY !!!!!\n",
    "i = 0\n",
    "tot = len(wikipedia_movie_IDS)\n",
    "\n",
    "for wiki_id in wikipedia_movie_IDS[0:20]:\n",
    "    print(wiki_id)\n",
    "    summary = list(open_parse_summary(wiki_id))\n",
    "    with open(\"./data/corenlp_summaries_words/\"+ wiki_id + \".txt\", 'w') as file_words:\n",
    "        for word in summary:\n",
    "            if word not in punctuation:\n",
    "                # write each item on a new line\n",
    "                file_words.write(\"%s\\n\" % word)\n",
    "    i += 1\n",
    "    print(str(i) + \"/\" + str(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9abc3af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26167604', '14075290', '24379585', '8683288', '18040146']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_movie_IDS[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b1dd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Actor gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450658</th>\n",
       "      <td>913762</td>\n",
       "      <td>Lord Feff</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450659</th>\n",
       "      <td>913762</td>\n",
       "      <td>Additional Voices</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450661</th>\n",
       "      <td>913762</td>\n",
       "      <td>UN Spacy Commander</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450662</th>\n",
       "      <td>913762</td>\n",
       "      <td>Silvie Gena</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450664</th>\n",
       "      <td>913762</td>\n",
       "      <td>Elensh</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182639 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia movie ID              Character name Actor gender\n",
       "0                   975900                    Akooshay            F\n",
       "1                   975900  Lieutenant Melanie Ballard            F\n",
       "2                   975900         Desolation Williams            M\n",
       "3                   975900          Sgt Jericho Butler            M\n",
       "4                   975900             Bashira Kincaid            F\n",
       "...                    ...                         ...          ...\n",
       "450658              913762                   Lord Feff            M\n",
       "450659              913762           Additional Voices            F\n",
       "450661              913762          UN Spacy Commander            M\n",
       "450662              913762                 Silvie Gena            F\n",
       "450664              913762                      Elensh            F\n",
       "\n",
       "[182639 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34df9155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 5.866478260869565 actors per movie\n"
     ]
    }
   ],
   "source": [
    "empty_count = 0\n",
    "avg_len = 0\n",
    "\n",
    "for wiki_id in wikipedia_movie_IDS:\n",
    "    test = char_to_gender[char_to_gender['Wikipedia movie ID'] == int(wiki_id)]\n",
    "    if(test.empty):\n",
    "        empty_count += 1\n",
    "    else:\n",
    "        avg_len += len(test)\n",
    "        \n",
    "avg_len /= (len(wikipedia_movie_IDS)-empty_count)\n",
    "\n",
    "print(\"Average of \" + str(avg_len) + \" actors per movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd5b7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords_and_general = spacy.lang.en.stop_words.STOP_WORDS\n",
    "#TODO: Add eventual additionnal words\n",
    "# Additional elements: man/wm/hb/wife cannot be processed as characters without more thorough language processing\n",
    "# Numbers: characters are sometimes described as for example 'Bartender 1', 'Bartender 2', these need to be avoided\n",
    "additional_elems = ['man', 'woman', 'husband', 'wife'] + ['0','1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "spacy_stopwords_and_general.update(additional_elems)\n",
    "\n",
    "def make_MF_repr(wiki_id):\n",
    "    with open(\"./data/corenlp_summaries_words/\"+ wiki_id + \".txt\", 'r') as summary_file:\n",
    "        #Read the summary\n",
    "        summary_text = summary_file.read().replace('\\n', ' ')\n",
    "        \n",
    "        #Get the characters from this movie\n",
    "        chars = char_to_gender[char_to_gender['Wikipedia movie ID'] == int(wiki_id)][['Character name', 'Actor gender']]\n",
    "        chars = dict(zip(chars['Character name'], chars['Actor gender']))\n",
    "        \n",
    "        #Remove punctuation from character names\n",
    "        for char_name in list(chars):\n",
    "            char_name_new = char_name\n",
    "            for pun in punctuation:\n",
    "                char_name_new = char_name_new.replace(pun, ' ')\n",
    "            chars[char_name_new] = chars.pop(char_name)\n",
    "        \n",
    "        #Remove characters which contain a stopword to keep (mostly) relevant characters (names).\n",
    "        for char_name in list(chars):\n",
    "            for word in char_name.split(' '):\n",
    "                if word.lower() in spacy_stopwords_and_general:\n",
    "                    chars.pop(char_name)\n",
    "                    break\n",
    "                    \n",
    "        #Replace character's names with M or F respectively\n",
    "        for char_name in list(chars):\n",
    "            summary_text = summary_text.replace(char_name, chars[char_name])\n",
    "            for word in char_name.split(' '):\n",
    "                summary_text = summary_text.replace(word, chars[char_name])\n",
    "                \n",
    "        # Save as final file format (M and F stay, other words get replaced by the number of words between two M/F)\n",
    "        # Each line is a new sentence\n",
    "        # For example, if the only character is named 'Bob' (man), 'Bob is cool be like Bob. I like Bob.' becomes:\n",
    "        # M4M\n",
    "        # 2M\n",
    "        #Check if chars list not empty\n",
    "        if(bool(chars)):\n",
    "            with open(\"./data/corenlp_summaries_encoded/\"+ wiki_id + \".txt\", 'w') as file_encoded:\n",
    "                count_non_character = 0\n",
    "                for word in summary_text.split(' '):\n",
    "                    if word == 'M' or word == 'F':\n",
    "                        if count_non_character != 0:\n",
    "                            file_encoded.write(\"%s\" % str(count_non_character))\n",
    "                        file_encoded.write(\"%s\" % word)\n",
    "                        count_non_character = 0\n",
    "                    elif word == '.':\n",
    "                        if count_non_character != 0:\n",
    "                            file_encoded.write(\"%s\" % str(count_non_character))\n",
    "                        file_encoded.write(\"\\n\")\n",
    "                        count_non_character = 0\n",
    "                    else:\n",
    "                        count_non_character += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0bb132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wiki_id in wikipedia_movie_IDS[0:20]:\n",
    "    make_MF_repr(wiki_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabb9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the total occurence of M/F characters in the summary.\n",
    "def count_pure_M_F(wiki_id):\n",
    "    with open(\"./data/corenlp_summaries_encoded/\"+ wiki_id + \".txt\", 'r') as summary_file:\n",
    "        summary_str = summary_file.read()\n",
    "        return summary_str.count('M'), summary_str.count('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "477482c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the occurence of M and F at a distance <= n. For ex. 'M2F' would give 1 for n=3 but 0 for n=2 or n=1\n",
    "# Not specifying n means taking the whole sentence\n",
    "def count_co_occ_M_F(wiki_id, n = 1000):\n",
    "    with open(\"./data/corenlp_summaries_encoded/\"+ wiki_id + \".txt\", 'r') as summary_file:\n",
    "        summary_str = summary_file.read()\n",
    "        co_occ_sum = {'M': 0, 'F': 0}\n",
    "        for line in summary_str.split('\\n'):\n",
    "            previous = ''\n",
    "            indic_hasbeencounted = 0\n",
    "            strint_saver = ''\n",
    "            for word in line:\n",
    "                if word == 'M' or word == 'F':\n",
    "                    if word != previous and previous and int(strint_saver) <= n-1:\n",
    "                        co_occ_sum[word] += 1\n",
    "                        if not indic_hasbeencounted:\n",
    "                            co_occ_sum[previous] += 1\n",
    "                       \n",
    "                        indic_hasbeencounted = 1\n",
    "                    else:\n",
    "                        indic_hasbeencounted = 0\n",
    "                    previous = word\n",
    "                    strint_saver = ''\n",
    "                else:\n",
    "                    strint_saver += word\n",
    "        return co_occ_sum['M'], co_occ_sum['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "666e3e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14075290\n",
      "P_M: 6 , P_F: 3 , c_M: 1 , c_F: 1\n",
      "18040146\n",
      "P_M: 5 , P_F: 0 , c_M: 0 , c_F: 0\n",
      "9149984\n",
      "P_M: 25 , P_F: 2 , c_M: 17 , c_F: 15\n",
      "34383775\n",
      "P_M: 5 , P_F: 5 , c_M: 5 , c_F: 5\n",
      "3113630\n",
      "P_M: 0 , P_F: 8 , c_M: 0 , c_F: 0\n",
      "26167604\n",
      "P_M: 15 , P_F: 2 , c_M: 4 , c_F: 3\n",
      "327582\n",
      "P_M: 7 , P_F: 0 , c_M: 0 , c_F: 0\n",
      "4298666\n",
      "P_M: 28 , P_F: 0 , c_M: 0 , c_F: 0\n",
      "5144523\n",
      "P_M: 0 , P_F: 0 , c_M: 0 , c_F: 0\n",
      "21411112\n",
      "P_M: 42 , P_F: 0 , c_M: 0 , c_F: 0\n",
      "2817162\n",
      "P_M: 21 , P_F: 0 , c_M: 0 , c_F: 0\n"
     ]
    }
   ],
   "source": [
    "files = [filename.split('.txt')[0] for filename in os.listdir('./data/corenlp_summaries_encoded/')]\n",
    "for wiki_id in files:\n",
    "    total_M, total_F = count_pure_M_F(wiki_id)\n",
    "    co_occ_M, co_occ_F = count_co_occ_M_F(wiki_id)\n",
    "    pure_M = total_M - co_occ_M\n",
    "    pure_F = total_F - co_occ_F\n",
    "    print(wiki_id)\n",
    "    print('P_M:', pure_M, ', P_F:', pure_F, ', c_M:', co_occ_M, ', c_F:', co_occ_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1055d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
